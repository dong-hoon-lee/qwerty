{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>비토리오</td>\n",
       "      <td>PER_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>양일</td>\n",
       "      <td>DAT_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>만에</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>영사관</td>\n",
       "      <td>ORG_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>감호</td>\n",
       "      <td>CVL_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769060</th>\n",
       "      <td>2</td>\n",
       "      <td>어째</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769061</th>\n",
       "      <td>3</td>\n",
       "      <td>뭔가</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769062</th>\n",
       "      <td>4</td>\n",
       "      <td>수상쩍은</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769063</th>\n",
       "      <td>5</td>\n",
       "      <td>좌담</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769064</th>\n",
       "      <td>6</td>\n",
       "      <td>．</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   src    tar\n",
       "0           1  비토리오  PER_B\n",
       "1           2    양일  DAT_B\n",
       "2           3    만에      -\n",
       "3           4   영사관  ORG_B\n",
       "4           5    감호  CVL_B\n",
       "...       ...   ...    ...\n",
       "769060      2    어째      -\n",
       "769061      3    뭔가      -\n",
       "769062      4  수상쩍은      -\n",
       "769063      5    좌담      -\n",
       "769064      6     ．      -\n",
       "\n",
       "[769065 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/prac_train_data.txt', names=['src', 'tar'], sep='\\t')\n",
    "train = train.reset_index()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>19</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769013</th>\n",
       "      <td>11</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769036</th>\n",
       "      <td>23</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769053</th>\n",
       "      <td>17</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769058</th>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769064</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57254 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index src tar\n",
       "15          6   .   -\n",
       "30         15   .   -\n",
       "40         10   .   -\n",
       "77         24   .   -\n",
       "96         19   .   -\n",
       "...       ...  ..  ..\n",
       "769013     11   .   -\n",
       "769036     23   .   -\n",
       "769053     17   .   -\n",
       "769058      5   .   -\n",
       "769064      6   .   -\n",
       "\n",
       "[57254 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['src'] = train['src'].str.replace('．', '.', regex=False)\n",
    "train.loc[train['src']=='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['src'] = train['src'].astype(str)\n",
    "train['tar'] = train['tar'].astype(str)\n",
    "\n",
    "train['src'] = train['src'].str.replace(r'[^ㄱ-ㅣ가-힣0-9a-zA-Z.]+', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>비토리오</td>\n",
       "      <td>PER_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>양일</td>\n",
       "      <td>DAT_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>만에</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>영사관</td>\n",
       "      <td>ORG_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>감호</td>\n",
       "      <td>CVL_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769060</th>\n",
       "      <td>2</td>\n",
       "      <td>어째</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769061</th>\n",
       "      <td>3</td>\n",
       "      <td>뭔가</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769062</th>\n",
       "      <td>4</td>\n",
       "      <td>수상쩍은</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769063</th>\n",
       "      <td>5</td>\n",
       "      <td>좌담</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769064</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   src    tar\n",
       "0           1  비토리오  PER_B\n",
       "1           2    양일  DAT_B\n",
       "2           3    만에      -\n",
       "3           4   영사관  ORG_B\n",
       "4           5    감호  CVL_B\n",
       "...       ...   ...    ...\n",
       "769060      2    어째      -\n",
       "769061      3    뭔가      -\n",
       "769062      4  수상쩍은      -\n",
       "769063      5    좌담      -\n",
       "769064      6     .      -\n",
       "\n",
       "[769065 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, '비토리오', 'PER_B'],\n",
       " [2, '양일', 'DAT_B'],\n",
       " [3, '만에', '-'],\n",
       " [4, '영사관', 'ORG_B'],\n",
       " [5, '감호', 'CVL_B'],\n",
       " [6, '용퇴', '-'],\n",
       " [7, '항룡', '-'],\n",
       " [8, '압력설', '-'],\n",
       " [9, '의심만', '-'],\n",
       " [10, '가율', '-'],\n",
       " [1, '이', '-'],\n",
       " [2, '음경동맥의', '-'],\n",
       " [3, '직경이', '-'],\n",
       " [4, '8', 'NUM_B'],\n",
       " [5, '19mm입니다', 'NUM_B'],\n",
       " [6, '.', '-'],\n",
       " [1, '9세이브로', 'NUM_B'],\n",
       " [2, '구완', '-'],\n",
       " [3, '30위인', 'NUM_B'],\n",
       " [4, 'LG', 'ORG_B']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [list(x) for x in train[['index','src','tar']].to_numpy()]\n",
    "\n",
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['tar'].unique().tolist()\n",
    "label_dict = {word:i for i, word in enumerate(label)}\n",
    "label_dict.update({'[PAD]':len(label_dict)})\n",
    "index_to_ner = {i:j for j, i in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER_B',\n",
       " 'DAT_B',\n",
       " '-',\n",
       " 'ORG_B',\n",
       " 'CVL_B',\n",
       " 'NUM_B',\n",
       " 'LOC_B',\n",
       " 'EVT_B',\n",
       " 'TRM_B',\n",
       " 'TRM_I',\n",
       " 'EVT_I',\n",
       " 'PER_I',\n",
       " 'CVL_I',\n",
       " 'NUM_I',\n",
       " 'TIM_B',\n",
       " 'TIM_I',\n",
       " 'ORG_I',\n",
       " 'DAT_I',\n",
       " 'ANM_B',\n",
       " 'MAT_B',\n",
       " 'MAT_I',\n",
       " 'AFW_B',\n",
       " 'FLD_B',\n",
       " 'LOC_I',\n",
       " 'AFW_I',\n",
       " 'PLT_B',\n",
       " 'FLD_I',\n",
       " 'ANM_I',\n",
       " 'PLT_I']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER_B': 0,\n",
       " 'DAT_B': 1,\n",
       " '-': 2,\n",
       " 'ORG_B': 3,\n",
       " 'CVL_B': 4,\n",
       " 'NUM_B': 5,\n",
       " 'LOC_B': 6,\n",
       " 'EVT_B': 7,\n",
       " 'TRM_B': 8,\n",
       " 'TRM_I': 9,\n",
       " 'EVT_I': 10,\n",
       " 'PER_I': 11,\n",
       " 'CVL_I': 12,\n",
       " 'NUM_I': 13,\n",
       " 'TIM_B': 14,\n",
       " 'TIM_I': 15,\n",
       " 'ORG_I': 16,\n",
       " 'DAT_I': 17,\n",
       " 'ANM_B': 18,\n",
       " 'MAT_B': 19,\n",
       " 'MAT_I': 20,\n",
       " 'AFW_B': 21,\n",
       " 'FLD_B': 22,\n",
       " 'LOC_I': 23,\n",
       " 'AFW_I': 24,\n",
       " 'PLT_B': 25,\n",
       " 'FLD_I': 26,\n",
       " 'ANM_I': 27,\n",
       " 'PLT_I': 28,\n",
       " '[PAD]': 29}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'PER_B',\n",
       " 1: 'DAT_B',\n",
       " 2: '-',\n",
       " 3: 'ORG_B',\n",
       " 4: 'CVL_B',\n",
       " 5: 'NUM_B',\n",
       " 6: 'LOC_B',\n",
       " 7: 'EVT_B',\n",
       " 8: 'TRM_B',\n",
       " 9: 'TRM_I',\n",
       " 10: 'EVT_I',\n",
       " 11: 'PER_I',\n",
       " 12: 'CVL_I',\n",
       " 13: 'NUM_I',\n",
       " 14: 'TIM_B',\n",
       " 15: 'TIM_I',\n",
       " 16: 'ORG_I',\n",
       " 17: 'DAT_I',\n",
       " 18: 'ANM_B',\n",
       " 19: 'MAT_B',\n",
       " 20: 'MAT_I',\n",
       " 21: 'AFW_B',\n",
       " 22: 'FLD_B',\n",
       " 23: 'LOC_I',\n",
       " 24: 'AFW_I',\n",
       " 25: 'PLT_B',\n",
       " 26: 'FLD_I',\n",
       " 27: 'ANM_I',\n",
       " 28: 'PLT_I',\n",
       " 29: '[PAD]'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['비토리오', 'PER_B']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tups = []\n",
    "temp_tup = []\n",
    "temp_tup.append(data[0][1:])\n",
    "\n",
    "for i, j, k in data:\n",
    "    if i != 1:\n",
    "        temp_tup.append([j, label_dict[k]])\n",
    "    if i == 1:\n",
    "        if len(temp_tup) != 0:\n",
    "            tups.append(temp_tup)\n",
    "            temp_tup = []\n",
    "            temp_tup.append([j, label_dict[k]])\n",
    "            \n",
    "tups.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['비토리오', 0], ['양일', 1], ['만에', 2], ['영사관', 3], ['감호', 4], ['용퇴', 2], ['항룡', 2], ['압력설', 2], ['의심만', 2], ['가율', 2]]\n",
      "[['이', 2], ['음경동맥의', 2], ['직경이', 2], ['8', 5], ['19mm입니다', 5], ['.', 2]]\n"
     ]
    }
   ],
   "source": [
    "print(tups[0])\n",
    "print(tups[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "targets = []\n",
    "\n",
    "for tup in tups:\n",
    "    sentence = []\n",
    "    target = []\n",
    "    sentence.append('[CLS]')\n",
    "    target.append(label_dict['-'])\n",
    "    \n",
    "    for i, j in tup:\n",
    "        sentence.append(i)\n",
    "        target.append(j)\n",
    "    \n",
    "    sentence.append('[SEP]')\n",
    "    target.append(label_dict['-'])\n",
    "    sentences.append(sentence)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '비토리오',\n",
       " '양일',\n",
       " '만에',\n",
       " '영사관',\n",
       " '감호',\n",
       " '용퇴',\n",
       " '항룡',\n",
       " '압력설',\n",
       " '의심만',\n",
       " '가율',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 1, 2, 3, 4, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_78b3253a26.model from cache at /Users/hoon/.cache/huggingface/transformers/7e55d7972628e6fc1babc614b5dd8bb43ab4f9d8541adc9fb1851112a7a7c5cc.4d2f4af7c2ca9df5b147978a95d38840e84801a378eee25756b008638e0bdc7f\n",
      "loading file https://huggingface.co/monologg/kobert/resolve/main/vocab.txt from cache at /Users/hoon/.cache/huggingface/transformers/efee434f5f4c5c89b5a7d8d5f30bbb0496f1540349fcfa21729cec5b96cfd2d1.719459e20bc981bc2093e859b02c3a3e51bab724d6b58927b23b512a3981229f\n",
      "loading file https://huggingface.co/monologg/kobert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/monologg/kobert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_config.json from cache at /Users/hoon/.cache/huggingface/transformers/d1c07e179f5e00959a3c8e4a150eaa4907dfe26544e4a71f2b0163982a476523.767d1b760a83978bae6c324157fad57ee513af333a7cea6986e852579f6f0dd1\n",
      "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /Users/hoon/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"monologg/kobert\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from tokenization_kobert import KoBertTokenizer\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁대한민국', '▁만', '세']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('대한민국 만세')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, txt_labels):\n",
    "    tokenized_sent = []\n",
    "    labels = []\n",
    "    \n",
    "    for word, label in zip(sentence, txt_labels):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "        \n",
    "        tokenized_sent.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "        \n",
    "    return tokenized_sent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_txt_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(sentences, targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS]',\n",
       "  '▁비',\n",
       "  '토',\n",
       "  '리',\n",
       "  '오',\n",
       "  '▁양',\n",
       "  '일',\n",
       "  '▁만에',\n",
       "  '▁영',\n",
       "  '사',\n",
       "  '관',\n",
       "  '▁감',\n",
       "  '호',\n",
       "  '▁용',\n",
       "  '퇴',\n",
       "  '▁항',\n",
       "  '룡',\n",
       "  '▁압력',\n",
       "  '설',\n",
       "  '▁의심',\n",
       "  '만',\n",
       "  '▁',\n",
       "  '가',\n",
       "  '율',\n",
       "  '[SEP]'],\n",
       " [2, 0, 0, 0, 0, 1, 1, 2, 3, 3, 3, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_txt_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_txt = [token_label_pair[0] for token_label_pair in tokenized_txt_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_txt_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁이',\n",
       " '▁음',\n",
       " '경',\n",
       " '동',\n",
       " '맥',\n",
       " '의',\n",
       " '▁직',\n",
       " '경',\n",
       " '이',\n",
       " '▁8',\n",
       " '▁19',\n",
       " 'mm',\n",
       " '입니다',\n",
       " '▁',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_txt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.array([len(x) for x in tokenized_txt]), 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 88\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 3647, 3606, 5424, 5872, 6172, 7095, 4349, 5424, 7096,  624,\n",
       "        548,  424, 7139,  517,   54,    3,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_txt],\n",
    "                          maxlen=max_len, dtype='int', value=0,\n",
    "                          truncating='post', padding='post')\n",
    "\n",
    "input_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  5,  5,  5,  5,  2,  2,  2,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pad_sequences([lab for lab in labels], maxlen=max_len, value=label_dict['[PAD]'],\n",
    "                     padding='post', dtype='int', truncating='post')\n",
    "\n",
    "tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.array([[int(i != 0) for i in ii] for ii in input_ids])\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /Users/hoon/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/monologg/kobert/resolve/main/pytorch_model.bin from cache at /Users/hoon/.cache/huggingface/transformers/9525d6f96682baa1f21538ea58d36263fe16a46345dd9637e3e28a4df2f9380f.ebe6e13ff204bebbffd4764cda3d5a97dc690a9c4110bde6d909ddc3ed5c4585\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at monologg/kobert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('monologg/kobert', num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
